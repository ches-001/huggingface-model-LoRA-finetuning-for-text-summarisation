{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Low Rank Adaptation and Parameter Efficient Finetuning of HuggingFace Flan-T5 LLMs on Text Summarisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, torch, json, random, gc\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    DataCollatorForSeq2Seq, \n",
    "    Seq2SeqTrainer, \n",
    "    Seq2SeqTrainingArguments, \n",
    "    pipeline\n",
    ")\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_int8_training,\n",
    "    TaskType,\n",
    "    PeftModel,\n",
    "    PeftConfig\n",
    ")\n",
    "from rouge import Rouge\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.schema import Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import Dict, Iterable\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"LLM_REPOSITORY\"] = \"google/flan-t5-small\"#\"philschmid/flan-t5-xxl-sharded-fp16\"\n",
    "os.environ[\"TOKENIZER_REPOSITORY\"] = \"google/flan-t5-small\"#\"google/flan-t5-xxl\"\n",
    "os.environ[\"EMBEDDINGS_MODEL\"] = \"all-MiniLM-L12-v2\"\n",
    "os.environ[\"MAX_TOKENS\"] = \"4096\"\n",
    "os.environ[\"DEVICE\"] = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"DATASET_PATH\"] = \"data/doc_summary_data\"\n",
    "os.environ[\"TOKENS_DATA_PATH\"] = F\"data/doc_summary_{os.environ['TOKENIZER_REPOSITORY'].split('/')[-1]}_tokens\"\n",
    "os.environ[\"SUMMARY_DATA_PATH\"] = \"data/doc_summary_pair.json\"\n",
    "os.makedirs(os.environ[\"DATASET_PATH\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"TOKENS_DATA_PATH\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA PREPARATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Training, Validation and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SIZE = 0.8\n",
    "VALIDATION_SIZE = 0.1\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "with open(os.environ[\"SUMMARY_DATA_PATH\"]) as f:\n",
    "    doc_summary_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "train_size = int(len(doc_summary_data) * TRAIN_SIZE)\n",
    "val_size = int(len(doc_summary_data) * VALIDATION_SIZE)\n",
    "test_size = int(len(doc_summary_data) * TEST_SIZE)\n",
    "\n",
    "train_data = doc_summary_data[:train_size]\n",
    "val_data = doc_summary_data[train_size:train_size+val_size]\n",
    "test_data = doc_summary_data[train_size+val_size:]\n",
    "\n",
    "data_list = [\n",
    "    (\"train\", train_data),\n",
    "    (\"validation\", val_data),\n",
    "    (\"test\", test_data),\n",
    "]\n",
    "\n",
    "for data_tuple in data_list:\n",
    "    with open(os.path.join(os.environ[\"DATASET_PATH\"], f\"{data_tuple[0]}.json\"), \"w\") as f:\n",
    "        json.dump(data_tuple[1], f, indent=4)\n",
    "    f.close()\n",
    "\n",
    "del doc_summary_data, train_data, val_data, test_data, data_list, data_tuple, train_size, val_size, test_size\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset into DictDataset Format to be modelled by the HuggingFace LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46670f6445af4c57a38c844ac7bbc33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f552f9708c4aadb62ad5a5dd4d57cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef2a0bb01914730b6c5ba15508d3a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136c19c553ba45f689ae0ce3dd9975bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3472d436f3224a438264ad849a286c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 4000\n",
      "Validation dataset size: 500\n",
      "Test dataset size: 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document': \"Crosse, Wisconsin, 54601, United States|Mayo Clinic Health System-Franciscan Healthcare, La Crosse, Wisconsin, 54601, United States|Dean Hematology and Oncology Clinic, Madison, Wisconsin, 53717, United States|Holy Family Memorial Hospital, Manitowoc, Wisconsin, 54221, United States|Aurora Bay Area Medical Group-Marinette, Marinette, Wisconsin, 54143, United States|Bay Area Medical Center, Marinette, Wisconsin, 54143, United States|Vince Lombardi Cancer Clinic-Marinette, Marinette, Wisconsin, 54143, United States|Marshfield Clinic, Marshfield, Wisconsin, 54449, United States|Aurora Cancer Care-Milwaukee, Milwaukee, Wisconsin, 53209, United States|Aurora Saint Luke's Medical Center, Milwaukee, Wisconsin, 53215, United States|Aurora Sinai Medical Center, Milwaukee, Wisconsin, 53233, United States|Marshfield Clinic-Minocqua Center, Minocqua, Wisconsin, 54548, United States|Green Bay Oncology - Oconto Falls, Oconto Falls, Wisconsin, 54154, United States|Vince Lombardi Cancer Clinic - Oshkosh, Oshkosh, Wisconsin,\",\n",
       " 'summary': 'The list provides healthcare facilities in different cities in Wisconsin, including hospitals, clinics, and cancer centers.',\n",
       " 'id': 3203}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(path=os.environ[\"DATASET_PATH\"])\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Validation dataset size: {len(dataset['validation'])}\")\n",
    "print(f\"Test dataset size: {len(dataset['test'])}\")\n",
    "dataset[\"train\"][random.randint(0, len(dataset[\"train\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corresponding LLM Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    os.environ[\"TOKENIZER_REPOSITORY\"],\n",
    "    model_max_length=int(os.environ[\"MAX_TOKENS\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tokenizer Object to retreive the Maximum Source (Text) and Target (Summary) Tokens in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1730535769a74558b0b2da6d18332268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab46ae455d449d7aff302a316882dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 428\n",
      "Max target length: 220\n"
     ]
    }
   ],
   "source": [
    "concatenated_dataset = concatenate_datasets(\n",
    "    [dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]]\n",
    ")\n",
    "tokenized_inputs = concatenated_dataset.map(\n",
    "    lambda x: tokenizer(x[\"document\"], truncation=True), batched=True, remove_columns=[\"document\", \"summary\"])\n",
    "\n",
    "tokenized_targets = concatenated_dataset.map(\n",
    "    lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True, remove_columns=[\"document\", \"summary\"])\n",
    "\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Dataset and Persist Tokens to Disk Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f4b781280344069a438da79d00889f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fddc63e02794248a2c828e1fc145f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2286a0d01854bceb1b51a935ecf7001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbd09247ad94bdb826230638e7355bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182b27376aeb417ab3d484e5ca1bdc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e15554de8d48408e45f2390db3d32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(sample, max_source_length: int, max_target_length: int, padding: str=\"max_length\"):\n",
    "    inputs = [f\"summarize this document: {item}\"  for item in sample[\"document\"]]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=max_source_length, \n",
    "        padding=padding, \n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=sample[\"summary\"], \n",
    "        max_length=max_target_length,\n",
    "        padding=padding, \n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else tokenizer.pad_token_id) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "preprocess_lambda = lambda dataset : preprocess_function(dataset, max_source_length, max_target_length)\n",
    "tokenized_dataset = dataset.map(preprocess_lambda, batched=True, remove_columns=[\"document\", \"summary\", \"id\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
    "\n",
    "# save datasets to disk for later easy loading\n",
    "tokenized_dataset[\"train\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"train\"))\n",
    "tokenized_dataset[\"validation\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"validation\"))\n",
    "tokenized_dataset[\"test\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL PREPARATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 8bits quantized HuggingFace LLM to Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.environ[\"LLM_REPOSITORY\"],\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Low Rank Adaptation Configurations Object and apply to Loaded LLM for Parameter Efficient Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 688,128 || all params: 77,649,280 || trainable%: 0.8862001038515747\n"
     ]
    }
   ],
   "source": [
    "# Define LoRA Config \n",
    "lora_config = LoraConfig(\n",
    " r=16, \n",
    " lora_alpha=32,\n",
    " target_modules=[\"q\", \"v\"],\n",
    " lora_dropout=0.05,\n",
    " bias=\"none\",\n",
    " task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "# prepare int-8 model for training\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Collator Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL FINETUNING / TRAINING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Seq2SeqTrainer Object and Commence LoRA Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4545' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4545/10000 58:46 < 1:10:33, 1.29 it/s, Epoch 9.09/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.782800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.745900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.722500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.711600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.672700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = F\"lora-{os.environ['LLM_REPOSITORY'].split('/')[-1]}\"\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "\tauto_find_batch_size=True,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    logging_dir=os.path.join(OUTPUT_DIR, \"logs\"),\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    ")\n",
    "model.config.use_cache = False  # to be set to True for inference\n",
    "\n",
    "# finetune model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist LoRA Model Weights to Disk Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('flan-t5-small_finetuned_results/tokenizer_config.json',\n",
       " 'flan-t5-small_finetuned_results/special_tokens_map.json',\n",
       " 'flan-t5-small_finetuned_results/spiece.model',\n",
       " 'flan-t5-small_finetuned_results/added_tokens.json',\n",
       " 'flan-t5-small_finetuned_results/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save our LoRA model & tokenizer results\n",
    "PEFT_MODEL_ID=f\"{os.environ['LLM_REPOSITORY'].split('/')[-1]}_finetuned_results\"\n",
    "trainer.model.save_pretrained(PEFT_MODEL_ID)\n",
    "tokenizer.save_pretrained(PEFT_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL EVALUATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LoRA Weights from Disk to Perform Inference on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load peft config for pre-trained checkpoint etc. \n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL_ID)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path,  load_in_8bit=True,  device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, PEFT_MODEL_ID, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Loaded Model and Tokenizer to Instantiate a Langchain HuggingFacePipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForSeq2SeqLM' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    }
   ],
   "source": [
    "# switch model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# define model pipeline\n",
    "hgf_pipeline = pipeline(\n",
    "    task=\"text2text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.1, \n",
    "    max_length=int(os.environ[\"MAX_TOKENS\"]),\n",
    "    top_p=0.15,\n",
    "    top_k=0,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=hgf_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Summaries from Documents in Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1938 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: page_content=\"States|Helen F Graham Cancer Center, Newark, Delaware, 19713, United States|University of Florida Health Science Center - Gainesville, Gainesville, Florida, 32610, United States|Memorial Regional Hospital/Joe DiMaggio Children's Hospital, Hollywood, Florida, 33021, United States|Mayo Clinic in Florida, Jacksonville, Florida, 32224-9980, United States|Miami Cancer Institute, Miami, Florida, 33176, United States|Orlando Health Cancer Institute, Orlando, Florida, 32806, United States|Memorial Hospital West, Pembroke Pines, Florida, 33028, United States|Emory University Hospital Midtown, Atlanta, Georgia, 30308, United States|Piedmont Hospital, Atlanta, Georgia, 30309, United States|Emory University Hospital/Winship Cancer Institute, Atlanta, Georgia, 30322, United States|Emory Saint Joseph's Hospital, Atlanta, Georgia, 30342, United States|John B Amos Cancer Center, Columbus, Georgia, 31904, United States|CTCA at Southeastern Regional Medical Center, Newnan, Georgia, 30265, United States|Lewis Hall Singletary\" metadata={}\n",
      "\n",
      "SUMARY: The summary provides a list of cancer centers and hospitals in different cities in Florida, including Jacksonville, Delaware, and Newnan.\n",
      "\n",
      "\n",
      "Document: page_content=\"Southeastern Regional Medical Center, Newnan, Georgia, 30265, United States|Lewis Hall Singletary Oncology Center, Thomasville, Georgia, 31792, United States|Queen's Medical Center, Honolulu, Hawaii, 96813, United States|The Cancer Center of Hawaii-Liliha, Honolulu, Hawaii, 96817, United States|Northwestern University, Chicago, Illinois, 60611, United States|Rush University Medical Center, Chicago, Illinois, 60612, United States|University of Illinois, Chicago, Illinois, 60612, United States|University of Chicago Comprehensive Cancer Center, Chicago, Illinois, 60637, United States|Decatur Memorial Hospital, Decatur, Illinois, 62526, United States|Northwestern Medicine Cancer Center Delnor, Geneva, Illinois, 60134, United States|Loyola University Medical Center, Maywood, Illinois, 60153, United States|Methodist Medical Center of Illinois, Peoria, Illinois, 61636, United States|Memorial Medical Center, Springfield, Illinois, 62781, United States|Southwest Illinois Health Services LLP, Swansea, Illinois, 62226,\" metadata={}\n",
      "\n",
      "SUMARY: This study includes medical centers and hospitals in different cities in the United States, including Georgia, Hawaii, and Illinois.\n",
      "\n",
      "\n",
      "Document: page_content='Illinois, 62781, United States|Southwest Illinois Health Services LLP, Swansea, Illinois, 62226, United States|Carle Cancer Center, Urbana, Illinois, 61801, United States|Northwestern Medicine Cancer Center Warrenville, Warrenville, Illinois, 60555, United States|Midwestern Regional Medical Center, Zion, Illinois, 60099, United States|Ascension Saint Vincent Anderson, Anderson, Indiana, 46016, United States|Parkview Hospital Randallia, Fort Wayne, Indiana, 46805, United States|Parkview Regional Medical Center, Fort Wayne, Indiana, 46845, United States|IU Health Ball Memorial Hospital, Muncie, Indiana, 47303, United States|Memorial Hospital of South Bend, South Bend, Indiana, 46601, United States|Ascension Via Christi Hospitals Wichita, Wichita, Kansas, 67214, United States|Owensboro Health Mitchell Memorial Cancer Center, Owensboro, Kentucky, 42303, United States|MaineHealth Coastal Cancer Treatment Center, Bath, Maine, 04530, United States|MaineHealth/SMHC Cancer Care and Blood Disorders-Biddeford,' metadata={}\n",
      "\n",
      "SUMARY: This summary provides a list of medical centers and hospitals in Illinois and Kentucky, including cancer centers and hospitals.\n",
      "\n",
      "\n",
      "Document: page_content='Bath, Maine, 04530, United States|MaineHealth/SMHC Cancer Care and Blood Disorders-Biddeford, Biddeford, Maine, 04005, United States|Maine Medical Center-Bramhall Campus, Portland, Maine, 04102, United States|MaineHealth Cancer Care Center of York County, Sanford, Maine, 04073, United States|MaineHealth/SMHC Cancer Care and Blood Disorders-Sanford, Sanford, Maine, 04073, United States|Maine Medical Center- Scarborough Campus, Scarborough, Maine, 04074, United States|University of Maryland/Greenebaum Cancer Center, Baltimore, Maryland, 21201, United States|Greater Baltimore Medical Center, Baltimore, Maryland, 21204, United States|UM Upper Chesapeake Medical Center, Bel Air, Maryland, 21014, United States|Central Maryland Radiation Oncology in Howard County, Columbia, Maryland, 21044, United States|Lahey Hospital and Medical Center, Burlington, Massachusetts, 01805, United States|Lowell General Hospital, Lowell, Massachusetts, 01854, United States|University of Michigan Comprehensive Cancer Center, Ann Arbor,' metadata={}\n",
      "\n",
      "SUMARY: This summary provides a list of medical centers and hospitals in Maine and Massachusetts, including cancer care and blood disorders.\n",
      "\n",
      "\n",
      "Document: page_content=\"Massachusetts, 01854, United States|University of Michigan Comprehensive Cancer Center, Ann Arbor, Michigan, 48109, United States|Henry Ford Cancer Institute-Downriver, Brownstown, Michigan, 48183, United States|GenesisCare USA - Clarkston, Clarkston, Michigan, 48346, United States|Henry Ford Macomb Hospital-Clinton Township, Clinton Township, Michigan, 48038, United States|Henry Ford Hospital, Detroit, Michigan, 48202, United States|GenesisCare USA - Farmington Hills, Farmington Hills, Michigan, 48334, United States|West Michigan Cancer Center, Kalamazoo, Michigan, 49007, United States|Saint Joseph Mercy Oakland, Pontiac, Michigan, 48341, United States|William Beaumont Hospital-Royal Oak, Royal Oak, Michigan, 48073, United States|GenesisCare USA - Troy, Troy, Michigan, 48098, United States|Henry Ford West Bloomfield Hospital, West Bloomfield, Michigan, 48322, United States|Mercy Hospital, Coon Rapids, Minnesota, 55433, United States|Saint Luke's Hospital of Duluth, Duluth, Minnesota, 55805, United\" metadata={}\n",
      "\n",
      "SUMARY: This summary provides a list of cancer centers and hospitals in Michigan, including their addresses and zip codes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "# summarise first 5 documents in the testing data\n",
    "predicted_summaries = []\n",
    "n_docs = 5\n",
    "for i, document in enumerate(dataset[\"test\"][\"document\"][:n_docs]):\n",
    "    document = Document(page_content=document)\n",
    "    summary = summary_chain.run([document])\n",
    "    print(f\"Document: {document}\\n\")\n",
    "    print(f\"SUMARY: {summary}\\n\\n\")\n",
    "    predicted_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PERFORMANCE MEASUREMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Generated Summaries to Target Summaries with the Rouge Score and the Cosine Similarity Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for summary 1: 0.8069508 \n",
      "\n",
      "Rouge scores for summary 1: {'rouge-1': {'r': 0.52, 'p': 0.7222222222222222, 'f': 0.6046511579232018}, 'rouge-2': {'r': 0.35714285714285715, 'p': 0.5263157894736842, 'f': 0.42553191007695795}, 'rouge-l': {'r': 0.48, 'p': 0.6666666666666666, 'f': 0.5581395300162251}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 2: 0.6042143 \n",
      "\n",
      "Rouge scores for summary 2: {'rouge-1': {'r': 0.2857142857142857, 'p': 0.35294117647058826, 'f': 0.3157894687396123}, 'rouge-2': {'r': 0.18181818181818182, 'p': 0.2222222222222222, 'f': 0.1999999950500001}, 'rouge-l': {'r': 0.23809523809523808, 'p': 0.29411764705882354, 'f': 0.26315788979224386}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 3: 0.69637465 \n",
      "\n",
      "Rouge scores for summary 3: {'rouge-1': {'r': 0.45, 'p': 0.6, 'f': 0.5142857093877552}, 'rouge-2': {'r': 0.2631578947368421, 'p': 0.3125, 'f': 0.28571428075102046}, 'rouge-l': {'r': 0.45, 'p': 0.6, 'f': 0.5142857093877552}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 4: 0.799549 \n",
      "\n",
      "Rouge scores for summary 4: {'rouge-1': {'r': 0.6086956521739131, 'p': 0.7777777777777778, 'f': 0.6829268243426534}, 'rouge-2': {'r': 0.5, 'p': 0.631578947368421, 'f': 0.5581395299513251}, 'rouge-l': {'r': 0.6086956521739131, 'p': 0.7777777777777778, 'f': 0.6829268243426534}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 5: 0.8459738 \n",
      "\n",
      "Rouge scores for summary 5: {'rouge-1': {'r': 0.7857142857142857, 'p': 0.6470588235294118, 'f': 0.709677414401665}, 'rouge-2': {'r': 0.6428571428571429, 'p': 0.5294117647058824, 'f': 0.5806451563371489}, 'rouge-l': {'r': 0.7857142857142857, 'p': 0.6470588235294118, 'f': 0.709677414401665}} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "embeddings_model = SentenceTransformer(os.environ[\"EMBEDDINGS_MODEL\"])\n",
    "embeddings_model.to(os.environ[\"DEVICE\"])\n",
    "target_summaries = dataset[\"test\"][\"summary\"][:n_docs]\n",
    "\n",
    "for i, (predicted_summary, target_summary) in enumerate(zip(predicted_summaries, target_summaries)):\n",
    "    pred_embeddings, target_embeddings = (\n",
    "        embeddings_model.encode(predicted_summary).reshape(1, -1),\n",
    "        embeddings_model.encode(target_summary).reshape(1, -1)\n",
    "    )\n",
    "    cos_similarity = cosine_similarity(target_embeddings, pred_embeddings)\n",
    "    rouge_scores = rouge.get_scores(predicted_summary, target_summary)\n",
    "    print(f\"Cosine similarity for summary {i+1}:\", cos_similarity[0][0], \"\\n\")\n",
    "    print(f\"Rouge scores for summary {i+1}:\", rouge_scores[0], \"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
