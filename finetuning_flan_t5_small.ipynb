{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Low Rank Adaptation and Parameter Efficient Finetuning of HuggingFace Flan-T5-SMALL LLM on Text Summarisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, torch, json, random, gc\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    DataCollatorForSeq2Seq, \n",
    "    Seq2SeqTrainer, \n",
    "    Seq2SeqTrainingArguments, \n",
    "    pipeline\n",
    ")\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_int8_training,\n",
    "    TaskType,\n",
    "    PeftModel,\n",
    "    PeftConfig\n",
    ")\n",
    "from rouge import Rouge\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.schema import Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import Dict, Iterable\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"LLM_REPOSITORY\"] = \"google/flan-t5-small\"#\"philschmid/flan-t5-xxl-sharded-fp16\"\n",
    "os.environ[\"TOKENIZER_REPOSITORY\"] = \"google/flan-t5-small\"#\"google/flan-t5-xxl\"\n",
    "os.environ[\"EMBEDDINGS_MODEL\"] = \"all-MiniLM-L12-v2\"\n",
    "os.environ[\"MAX_TOKENS\"] = \"4096\"\n",
    "os.environ[\"DEVICE\"] = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"DATASET_PATH\"] = \"data/doc_summary_data\"\n",
    "os.environ[\"TOKENS_DATA_PATH\"] = F\"data/doc_summary_{os.environ['TOKENIZER_REPOSITORY'].split('/')[-1]}_tokens\"\n",
    "os.environ[\"SUMMARY_DATA_PATH\"] = \"data/doc_summary_pair.json\"\n",
    "os.makedirs(os.environ[\"DATASET_PATH\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"TOKENS_DATA_PATH\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA PREPARATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Training, Validation and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SIZE = 0.8\n",
    "VALIDATION_SIZE = 0.1\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "with open(os.environ[\"SUMMARY_DATA_PATH\"]) as f:\n",
    "    doc_summary_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "train_size = int(len(doc_summary_data) * TRAIN_SIZE)\n",
    "val_size = int(len(doc_summary_data) * VALIDATION_SIZE)\n",
    "test_size = int(len(doc_summary_data) * TEST_SIZE)\n",
    "\n",
    "train_data = doc_summary_data[:train_size]\n",
    "val_data = doc_summary_data[train_size:train_size+val_size]\n",
    "test_data = doc_summary_data[train_size+val_size:]\n",
    "\n",
    "data_list = [\n",
    "    (\"train\", train_data),\n",
    "    (\"validation\", val_data),\n",
    "    (\"test\", test_data),\n",
    "]\n",
    "\n",
    "for data_tuple in data_list:\n",
    "    with open(os.path.join(os.environ[\"DATASET_PATH\"], f\"{data_tuple[0]}.json\"), \"w\") as f:\n",
    "        json.dump(data_tuple[1], f, indent=4)\n",
    "    f.close()\n",
    "\n",
    "del doc_summary_data, train_data, val_data, test_data, data_list, data_tuple, train_size, val_size, test_size\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset into DictDataset Format to be modelled by the HuggingFace LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/doc_summary_data to /home/ubuntu/.cache/huggingface/datasets/json/doc_summary_data-786ffbbe80ba07a0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9713073c33934d9682fc0a2e57493118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e436cbf9051455bbfc175eee89bb243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bc86197d1c44ad9f3a31cd7ebf160a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617448900dba4f1db8b9697abe6d7b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ceb7fcfeb94654a71d825c6f2842d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/ubuntu/.cache/huggingface/datasets/json/doc_summary_data-786ffbbe80ba07a0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1df6ade8db44657b002167304581e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 1507\n",
      "Validation dataset size: 188\n",
      "Test dataset size: 189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document': 'NCT Number: NCT03018080\\nStudy Title: Pilot Study of Paclitaxel Plus Pembrolizumab in Metastatic HER2-Negative Breast Cancer\\nStudy URL: https://beta.clinicaltrials.gov/study/NCT03018080\\nAcronym: PePPy\\nStudy Status: COMPLETED\\nBrief Summary: The primary objective of this study is to assess the safety and feasibility of the following two regimens: Cohort A) phased regimen of pembrolizumab in which paclitaxel is followed by paclitaxel plus pembrolizumab and Cohort B) concurrent regimen of paclitaxel plus pembrolizumab. The primary safety objective is to evaluate the overall grade 3 or 4 treatment-related adverse event rate for each cohort and compare them to relevant historical controls.\\nStudy Results: YES\\nConditions: Breast - Female|Male Breast Cancer\\nInterventions: DRUG: Pembrolizumab|DRUG: Paclitaxel\\nPrimary Outcome Measures: Number of Participants With at Least One Grade 3 or 4 Treatment-related Adverse Event, Grade 3 or 4 study treatment-related adverse events will be determined for each subject as a binary variable indicating whether or not the subject experienced at least one grade 3 or 4 study treatment-related adverse events according to the NCI Common Terminology for Adverse Events, version 4.0. An adverse event will be considered study treatment related if it is determined that the event is at least possibly related to either paclitaxel, pembrolizumab, or both., From enrollment to at least 30 days following cessation of study treatment. The median time on treatment was 5.5 months.',\n",
       " 'summary': 'The study evaluated the safety and feasibility of two treatment regimens for metastatic HER2-negative breast cancer. The primary objective was to assess the rate of severe treatment-related adverse events. The study has been completed, and the median time on treatment was 5.5 months.',\n",
       " 'id': 1255}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(path=os.environ[\"DATASET_PATH\"])\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Validation dataset size: {len(dataset['validation'])}\")\n",
    "print(f\"Test dataset size: {len(dataset['test'])}\")\n",
    "dataset[\"train\"][random.randint(0, len(dataset[\"train\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corresponding LLM Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c6080d528d499f98be8406329289d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c499f7e57254239b689cd49df1135dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6333922912e1487aa35c218bffd78d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee71e9ce94e24f8a84f4c76cb8cd1526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    os.environ[\"TOKENIZER_REPOSITORY\"],\n",
    "    model_max_length=int(os.environ[\"MAX_TOKENS\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tokenizer Object to retreive the Maximum Source (Text) and Target (Summary) Tokens in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad0f3ee41ba486a945bae5eb1bc39ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70be122668024becafa7fa4109d270ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 1363\n",
      "Max target length: 218\n"
     ]
    }
   ],
   "source": [
    "concatenated_dataset = concatenate_datasets(\n",
    "    [dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]]\n",
    ")\n",
    "tokenized_inputs = concatenated_dataset.map(\n",
    "    lambda x: tokenizer(x[\"document\"], truncation=True), batched=True, remove_columns=[\"document\", \"summary\"])\n",
    "\n",
    "tokenized_targets = concatenated_dataset.map(\n",
    "    lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True, remove_columns=[\"document\", \"summary\"])\n",
    "\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Dataset and Persist Tokens to Disk Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b2f5aa4eb44473bc6c67e777fe3498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e4b0415fa14e8486df49de5bdad841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/188 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fbdf132a2b4901b55e213892f2e3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1308b653e84270807f437e793e8e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea403405d7b54db0891ea1cd4f49c229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/188 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab81c741f2846eba94b676b79ea87a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(sample, max_source_length: int, max_target_length: int, padding: str=\"max_length\"):\n",
    "    inputs = [f\"summarize this document: {item}\"  for item in sample[\"document\"]]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=max_source_length, \n",
    "        padding=padding, \n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=sample[\"summary\"], \n",
    "        max_length=max_target_length,\n",
    "        padding=padding, \n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else tokenizer.pad_token_id) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "preprocess_lambda = lambda dataset : preprocess_function(dataset, max_source_length, max_target_length)\n",
    "tokenized_dataset = dataset.map(preprocess_lambda, batched=True, remove_columns=[\"document\", \"summary\", \"id\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
    "\n",
    "# save datasets to disk for later easy loading\n",
    "tokenized_dataset[\"train\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"train\"))\n",
    "tokenized_dataset[\"validation\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"validation\"))\n",
    "tokenized_dataset[\"test\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL PREPARATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 8bits quantized HuggingFace LLM to Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa580e0cd83242969caae31e4065a779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa69ba132d3f4e399109bde4076e9897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb49af4985d45e8ae1cda25ff6d588d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.environ[\"LLM_REPOSITORY\"],\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Low Rank Adaptation Configurations Object and apply to Loaded LLM for Parameter Efficient Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 688,128 || all params: 77,649,280 || trainable%: 0.8862001038515747\n"
     ]
    }
   ],
   "source": [
    "# Define LoRA Config \n",
    "lora_config = LoraConfig(\n",
    " r=16, \n",
    " lora_alpha=32,\n",
    " target_modules=[\"q\", \"v\"],\n",
    " lora_dropout=0.05,\n",
    " bias=\"none\",\n",
    " task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "# prepare int-8 model for training\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Collator Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL FINETUNING / TRAINING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Seq2SeqTrainer Object and Commence LoRA Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [945/945 12:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.239500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=945, training_loss=2.600633861400463, metrics={'train_runtime': 780.4079, 'train_samples_per_second': 9.655, 'train_steps_per_second': 1.211, 'total_flos': 3785013953740800.0, 'train_loss': 2.600633861400463, 'epoch': 5.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = F\"lora-{os.environ['LLM_REPOSITORY'].split('/')[-1]}\"\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "\tauto_find_batch_size=True,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    logging_dir=os.path.join(OUTPUT_DIR, \"logs\"),\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    ")\n",
    "model.config.use_cache = False  # to be set to True for inference\n",
    "\n",
    "# finetune model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist LoRA Model Weights to Disk Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('flan-t5-small_finetuned_results/tokenizer_config.json',\n",
       " 'flan-t5-small_finetuned_results/special_tokens_map.json',\n",
       " 'flan-t5-small_finetuned_results/spiece.model',\n",
       " 'flan-t5-small_finetuned_results/added_tokens.json',\n",
       " 'flan-t5-small_finetuned_results/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save our LoRA model & tokenizer results\n",
    "PEFT_MODEL_ID=f\"{os.environ['LLM_REPOSITORY'].split('/')[-1]}_finetuned_results\"\n",
    "trainer.model.save_pretrained(PEFT_MODEL_ID)\n",
    "tokenizer.save_pretrained(PEFT_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL EVALUATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LoRA Weights from Disk to Perform Inference on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load peft config for pre-trained checkpoint etc. \n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL_ID)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path,  load_in_8bit=True,  device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, PEFT_MODEL_ID, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Loaded Model and Tokenizer to Instantiate a Langchain HuggingFacePipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForSeq2SeqLM' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    }
   ],
   "source": [
    "# switch model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# define model pipeline\n",
    "hgf_pipeline = pipeline(\n",
    "    task=\"text2text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.1, \n",
    "    max_length=int(os.environ[\"MAX_TOKENS\"]),\n",
    "    top_p=0.15,\n",
    "    top_k=0,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=hgf_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Summaries from Documents in Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638ac456b33443cc856f0f452e4a66cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a156ec86a74d2994294e886c3d025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5391e6460cce4f26805fa36ddaf76453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6476ad66f40744349e2e50579395d77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: page_content='NCT Number: NCT02289898\\nStudy Title: Study of Gemcitabine, Abraxane® Plus Placebo Versus Gemcitabine, Abraxane® Plus 1 or 2 Truncated Courses of Demcizumab in Subjects With 1st-Line Metastatic Pancreatic Ductal Adenocarcinoma\\nStudy URL: https://beta.clinicaltrials.gov/study/NCT02289898\\nAcronym: YOSEMITE\\nStudy Status: COMPLETED\\nBrief Summary: This is a randomized, double blind, 3 arm (1:1:1) study in subjects with 1st-line metastatic pancreatic ductal adenocarcinoma.' metadata={}\n",
      "\n",
      "SUMARY: This study examined the effectiveness of Demcizumab in treating 1st-line metastatic pancreatic ductal adenocarcinoma. The study included Gemcitabine, Abraxane® Plus Placebo Versus Gemcitabine, Abraxane® Plus 1 or 2 Truncated Courses of Demcizumab in subjects with 1st-line metastatic pancreatic ductal adenocarcinoma. The study was completed and the results were completed.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: page_content='The purpose is to test the efficacy and safety of demcizumab, when given in combination with gemcitabine and Abraxane® compared to placebo. The administration of gemcitabine and Abraxane® is a standard treatment for patients with metastatic pancreatic ductal adenocarcinoma.\\nStudy Results: YES\\nConditions: Pancreatic Cancer\\nInterventions: DRUG: Demcizumab|DRUG: Abraxane®|DRUG: gemcitabine|DRUG: Placebo\\nPrimary Outcome Measures: Hazard of Progression in the Placebo/Placebo Arm and the Pooled Demcizumab Arms, Investigator assessed Kaplan-Meier estimates of progression-free survival for placebo/placebo arm and pooled demcizumab arm., Investigator-assessed progression-free survival time through duration of the study (2 years, 23 days).\\nSecondary Outcome Measures: unknown\\nOther Outcome Measures: unknown\\nSponsor: OncoMed Pharmaceuticals, Inc.\\nCollaborators: Celgene Corporation\\nSex: ALL\\nAge: ADULT, OLDER_ADULT\\nPhases: PHASE2\\nEnrollment: 207\\nFunder Type: INDUSTRY\\nStudy Type: INTERVENTIONAL\\nStudy Design: Allocation: RANDOMIZED|Intervention Model: PARALLEL|Masking: TRIPLE (PARTICIPANT, INVESTIGATOR, OUTCOMES_ASSESSOR)|Primary Purpose: TREATMENT\\nOther IDs: M18-006\\nStart Date: 2015-04-20\\nPrimary Completion Date: 2017-05\\nCompletion Date: 2017-09\\nFirst Posted: 2014-11-13\\nResults First Posted: 2018-05-21\\nLast Update Posted: 2020-09-28' metadata={}\n",
      "\n",
      "SUMARY: The study examined the effectiveness and safety of demcizumab in combination with gemcitabine and Abraxane®. The study enrolled 207 participants and was sponsored by Celgene Corporation.\n",
      "\n",
      "\n",
      "Document: page_content=\"Other IDs: M18-006\\nStart Date: 2015-04-20\\nPrimary Completion Date: 2017-05\\nCompletion Date: 2017-09\\nFirst Posted: 2014-11-13\\nResults First Posted: 2018-05-21\\nLast Update Posted: 2020-09-28\\nLocations: Banner MD Anderson Cancer Center, Gilbert, Arizona, 85234, United States|Providence Saint Joseph Medical Center, Burbank, California, 91505, United States|City of Hope, Duarte, California, 91010, United States|Scripps Cancer Center, La Jolla, California, 92037, United States|University of California, Davis Comprehensive Cancer Center, Sacramento, California, 95817, United States|Soulhern California Permanente Medical Group, San Marcos, California, 92078, United States|Kaiser Permanente Medical Center, Vallejo, California, 94589, United States|Rocky Mountain Cancer Centers, Denver, Colorado, 80218, United States|Lynn Cancer Institute, Boca Raton, Florida, 33486, United States|University of Iowa Hospitals and Clinics, Iowa City, Iowa, 52242, United States|University of Kansas Cancer Center, Westwood, Kansas, 66205, United States|Ochsner Clinic Foundation, New Orleans, Louisiana, 70121, United States|University of Michigan, Ann Arbor, Michigan, 48109, United States|Dartmouth Hitchcock Medical Center, Norris Cotton Cancer Center, Lebanon, New Hampshire, 03756, United States|University of Rochester, Rochester, New York, 14642, United States|SUNY Upstate Medical University, Syracuse, New York, 13210, United States|Cleveland Clinic, Cleveland, Ohio, 44195, United States|Kaiser Permanente NW Oncology Research, Portland, Oregon, 97227, United States|Thomas Jefferson University, Sydney Kimmel Cancer Center, Philadelphia, Pennsylvania, 19107, United States|Baylor College of Medicine, Houston, Texas, 77030, United States|Joe Arrington Cancer Research Treatment Center, Lubbock, Texas, 79410, United States|Huntsman Cancer Institute at The University of Utah, Salt Lake City, Utah, 84112, United States|Prince of Wales Hospital, Randwick, New South Wales, 2031, Australia|Monash Medical Centre, Moorabbin, Bentleigh East, Victoria, 3165, Australia|Western Health (Sunshine Hospitals), St Albans, Victoria, 3021, Australia|St John of God Murdoch Hospital, Murdoch, Western Australia, 6150, Australia|St. John of God Subiaco Hospital, Subiaco, Western Australia, 6008, Australia|Hopital Erasme, Brussels, Brussels Capital, 1070, Belgium|Tom Baker Cancer Centre, Calgary, Alberta, T2N 4N2, Canada|British Columbia Cancer Agency, Vancouver, British Columbia, V5Z 4E6, Canada|QEII Health Sciences Centre, Halifax, Nova Scotia, B3H 2Y9, Canada|London Regional Cancer Program, London, Ontario, N6A 4L6, Canada|Sunnybrook Health Sciences Centre, Odette Cancer Centre, Toronto, Ontario, M4N 3M5, Canada|Princess Margaret Hospital, Toronto, Ontario, M5G 2M9, Canada|St Josephs Health Centre, Toronto, Ontario, M6R 1B5, Canada|Hospital Universitario de Fuenlabrada, Fuenlabrada, Madrid, 28492, Spain|Hospital Universitari Germans Trias i Pujol - lnstituto Catalan d'Oncologia (!CO), Barcelona, 08916, Spain|Hospital General Universitario Gregorio Marafi6n, Madrid, 28007, Spain|Hospital Universitario de Fuenlabrada, Madrid, 28942, Spain|Hospital Universitario Miguel Servet, Zaragoza, 50009, Spain|Bristol Haematology & Oncology Centre, Bristol, BS2 8ED, United Kingdom|Sarah Cannon Research Institute UK, London, W1G 6AD, United Kingdom\\nStudy Documents: Statistical Analysis Plan|Study Protocol and Informed Consent Form\" metadata={}\n",
      "\n",
      "SUMARY: The study is being conducted at Banner MD Anderson Cancer Center and the University of Kansas Cancer Center. The study is being conducted at Banner MD Anderson Cancer Center, University of Utah, and Queensland.\n",
      "\n",
      "\n",
      "Document: page_content='NCT Number: NCT03578081\\nStudy Title: Olanzapine With or Without Fosaprepitant Dimeglumine in Preventing Chemotherapy Induced Nausea and Vomiting in Cancer Patients Receiving Highly Emetogenic Chemotherapy\\nStudy URL: https://beta.clinicaltrials.gov/study/NCT03578081\\nAcronym: unknown\\nStudy Status: COMPLETED\\nBrief Summary: This randomized phase III trial studies how well olanzapine with or without fosaprepitant work in preventing chemotherapy induced nausea and vomiting in cancer patients receiving chemotherapy that causes vomiting. Olanzapine and fosaprepitant dimeglumine may help control nausea and vomiting in patients during chemotherapy. Olanzapine is usually given in combination with other drugs, including fosaprepitant dimeglumine. It is not yet known if olanzapine when given with other drugs, is still effective without using fosaprepitant dimeglumine for controlling nausea and vomiting.\\nStudy Results: YES\\nConditions: Malignant Neoplasm\\nInterventions: DRUG: Palonosetron Hydrochloride|DRUG: Ondansetron Hydrochloride|DRUG: Dexamethasone|DRUG: Fosaprepitant Dimeglumine|DRUG: Olanzapine|OTHER: Placebo\\nPrimary Outcome Measures: No Nausea Rate Defined as a Response of 0 in the Nausea Item of Nausea and Vomiting Daily Diary/Questionnaire in the Overall (0-120 Hours), Acute (0-24 Hours), and Delayed (24-120 Hours) Periods, The specific measure will be based on the proportion of patients with a value of 0, as measured by the single nausea item (scale 0-10, 0 is no symptoms, 10 is worst symptoms) of the Questionnaire. A modified intent-to-treat principle will be applied for statistical analysis of efficacy in evaluable patients. The proportions of patients with no nausea during the overall, the acute, and the delayed period will be summarized by treatment arm. They will be tested in a sequential manner, using a Simes gatekeeping procedure to maintain the overall significance level at the specified by the Lan-DeMets family of alpha spending function. The difference in no nausea proportions between arms will be estimated along with a one-sided 95% confidence interval. The tests and the confidence intervals will be constructed using normal approximation of the binomial distribution adjusted for the non-inferiority margin., Up to 120 hours' metadata={}\n",
      "\n",
      "SUMARY: This study is investigating the effectiveness of olanzapine with or without fosaprepitant dimeglumine in preventing vomiting and vomiting in cancer patients receiving highly emetogenic chemotherapy. The study is currently completed.\n",
      "\n",
      "\n",
      "Document: page_content='Secondary Outcome Measures: Complete Response (CR) (no Emetic Episodes and no Use of Rescue Medication) During the Acute, Delayed and the Overall Periods as Measured by the Nausea and Vomiting Daily Diary/Questionnaire, The specific measure will be based on the proportion of patients who answered \"None\" to both questions concerning Vomiting episode(None, Once, Twice, More than twice) and number of extra nausea/vomiting pills taken (None, One, Two, More than two) in the Nausea and Vomiting Daily Diary/Questionnaire. The CR rate for the overall, the acute, and the delayed period will be summarized by treatment arm and will be compared using a Chi-squared test. The difference in CR rates between arms will be estimated along with a 95% confidence interval., Up to 120 hours|Potential Toxicities as Ascribed to Olanzapine as Measured by the Nausea and Vomiting Daily Diary/Questionnaire, Potential toxicities includes nausea, undesired sedation, and undesired appetite, measured by three individual items ( nausea, undesired sedation, undesired appetite) of the Nausea and Vomiting Daily Dairy/Questionnaire(scale 0-10, 0 is no symptoms, 10 is worst symptoms). Incidences of toxicities will be summarized by type and by treatment arm. Incidences of toxicities will be compared between arms using a Chi-squared test or the Fisher\\'s exact test as appropriate. In addition, undesired sedation and appetite increase as collected in the Nausea and Vomiting Daily Diary/Questionnaire will be analyzed by repeated measures analyses including descriptive statistics, graphical approaches, and growth curve models to account for the factor of day and time trend., Up to 120 hours|Average Nausea Scores (0-10) Repeatedly Measured by the Nausea and Vomiting Daily Diary/Questionnaire, The specific measure will be based on the by the single nausea item (scale 0-10, 0 is no symptoms, 10 is worst symptoms) of the Nausea and Vomiting Daily Diary/Questionnaire. Nausea scores (0-10) repeatedly measured by the Nausea and Vomiting Daily Diary/Questionnaire will be analyzed using the repeated measures analyses and growth curve models as described above for undesired sedation and increase in appetite., Up to 1 year|Total Frequency of Rescue Medication as Measured by the Nausea and Vomiting Daily Diary/Questionnaire, The specific measure will be based on the single item : number of extra nausea/vomiting pills taken (None, One , Twice, More than twice) of the Nausea and Vomiting Daily Diary/Questionnaire., Over 5 Days per each of the 4 cycles\\nOther Outcome Measures: unknown\\nSponsor: Alliance for Clinical Trials in Oncology\\nCollaborators: National Cancer Institute (NCI)\\nSex: ALL\\nAge: ADULT, OLDER_ADULT\\nPhases: PHASE3\\nEnrollment: 690\\nFunder Type: OTHER\\nStudy Type: INTERVENTIONAL\\nStudy Design: Allocation: RANDOMIZED|Intervention Model: PARALLEL|Masking: DOUBLE (PARTICIPANT, INVESTIGATOR)|Primary Purpose: SUPPORTIVE_CARE\\nOther IDs: A221602|NCI-2017-02410|UG1CA189823\\nStart Date: 2018-10-15\\nPrimary Completion Date: 2021-11-08\\nCompletion Date: 2023-05-01\\nFirst Posted: 2018-07-05\\nResults First Posted: 2023-02-09\\nLast Update Posted: 2023-05-08' metadata={}\n",
      "\n",
      "SUMARY: The Alliance for Clinical Trials in Oncology conducted a study to assess the effectiveness of a treatment for vomiting and nausea. The study was sponsored by Alliance for Clinical Trials in Oncology and funded by Alliance for Clinical Trials in Oncology. The study was sponsored by Alliance for Clinical Trials in Oncology and sponsored by Alliance for Clinical Trials in Oncology. The results were posted on May 5, 2023, and the final update was posted on May 5, 2023.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "# summarise first 5 documents in the testing data\n",
    "predicted_summaries = []\n",
    "n_docs = 5\n",
    "for i, document in enumerate(dataset[\"test\"][\"document\"][:n_docs]):\n",
    "    document = Document(page_content=document)\n",
    "    summary = summary_chain.run([document])\n",
    "    print(f\"Document: {document}\\n\")\n",
    "    print(f\"SUMARY: {summary}\\n\\n\")\n",
    "    predicted_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PERFORMANCE MEASUREMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Generated Summaries to Target Summaries with the Rouge Score and the Cosine Similarity Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for summary 1: 0.5967611 \n",
      "\n",
      "Rouge scores for summary 1: {'rouge-1': {'r': 0.42857142857142855, 'p': 0.36363636363636365, 'f': 0.3934426179844129}, 'rouge-2': {'r': 0.16666666666666666, 'p': 0.13157894736842105, 'f': 0.14705881859861608}, 'rouge-l': {'r': 0.39285714285714285, 'p': 0.3333333333333333, 'f': 0.36065573273851115}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 2: 0.6732583 \n",
      "\n",
      "Rouge scores for summary 2: {'rouge-1': {'r': 0.37777777777777777, 'p': 0.7727272727272727, 'f': 0.5074626821563823}, 'rouge-2': {'r': 0.24074074074074073, 'p': 0.5416666666666666, 'f': 0.33333332907297836}, 'rouge-l': {'r': 0.37777777777777777, 'p': 0.7727272727272727, 'f': 0.5074626821563823}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 3: 0.35317606 \n",
      "\n",
      "Rouge scores for summary 3: {'rouge-1': {'r': 0.07317073170731707, 'p': 0.15789473684210525, 'f': 0.0999999956722224}, 'rouge-2': {'r': 0.02040816326530612, 'p': 0.045454545454545456, 'f': 0.028169009807578513}, 'rouge-l': {'r': 0.07317073170731707, 'p': 0.15789473684210525, 'f': 0.0999999956722224}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 4: 0.9231314 \n",
      "\n",
      "Rouge scores for summary 4: {'rouge-1': {'r': 0.38636363636363635, 'p': 0.6538461538461539, 'f': 0.485714281044898}, 'rouge-2': {'r': 0.2545454545454545, 'p': 0.5, 'f': 0.3373493931194658}, 'rouge-l': {'r': 0.38636363636363635, 'p': 0.6538461538461539, 'f': 0.485714281044898}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 5: 0.7678033 \n",
      "\n",
      "Rouge scores for summary 5: {'rouge-1': {'r': 0.38181818181818183, 'p': 0.6363636363636364, 'f': 0.4772727225852274}, 'rouge-2': {'r': 0.1282051282051282, 'p': 0.2222222222222222, 'f': 0.1626016213761651}, 'rouge-l': {'r': 0.34545454545454546, 'p': 0.5757575757575758, 'f': 0.4318181771306819}} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "embeddings_model = SentenceTransformer(os.environ[\"EMBEDDINGS_MODEL\"])\n",
    "embeddings_model.to(os.environ[\"DEVICE\"])\n",
    "target_summaries = dataset[\"test\"][\"summary\"][:n_docs]\n",
    "\n",
    "for i, (predicted_summary, target_summary) in enumerate(zip(predicted_summaries, target_summaries)):\n",
    "    pred_embeddings, target_embeddings = (\n",
    "        embeddings_model.encode(predicted_summary).reshape(1, -1),\n",
    "        embeddings_model.encode(target_summary).reshape(1, -1)\n",
    "    )\n",
    "    cos_similarity = cosine_similarity(target_embeddings, pred_embeddings)\n",
    "    rouge_scores = rouge.get_scores(predicted_summary, target_summary)\n",
    "    print(f\"Cosine similarity for summary {i+1}:\", cos_similarity[0][0], \"\\n\")\n",
    "    print(f\"Rouge scores for summary {i+1}:\", rouge_scores[0], \"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
